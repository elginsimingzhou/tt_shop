# -*- coding: utf-8 -*-
"""tiktok_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HRrP_eaS16DWnD6_cMh48xIx2bAxmCH0
"""

!pip install pytesseract opencv-python-headless ultralytics nltk scikit-learn rake-nltk
!sudo apt-get install tesseract-ocr

import cv2
from ultralytics import YOLO
import pytesseract
import re
import requests
from nltk.corpus import stopwords, words
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet
from sklearn.feature_extraction.text import TfidfVectorizer
from rake_nltk import Rake
import os

# Download necessary NLTK data
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('words')
nltk.download('wordnet')

def download_video(url, file_path):
    response = requests.get(url, stream=True)
    if response.status_code == 200:
        with open(file_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=1024):
                f.write(chunk)
    else:
        raise Exception(f"Failed to download video from {url}")

def extract_frames(video_path, num_frames=10):
    cap = cv2.VideoCapture(video_path)
    frames = []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_indices = [int(i * total_frames / num_frames) for i in range(num_frames)]

    for idx in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            break
        if idx in frame_indices:
            frames.append(frame)

    cap.release()
    return frames

def detect_objects(model, frames):
    results = []
    for frame in frames:
        # Convert frame to RGB (YOLO expects RGB images)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Run inference with a low confidence threshold
        predictions = model.predict(rgb_frame, conf=0.5)  # Adjust confidence threshold here


        for result in predictions:
            boxes = result.boxes
            for box in boxes:
                cls = box.cls.item()
                label = model.names[int(cls)]
                results.append(label)
    return results

def extract_text(frames):
    text_results = []
    for frame in frames:
        # Run OCR on the frame
        text = pytesseract.image_to_string(frame)

        # Basic text processing
        text = text.lower()
        text = re.sub(r'\W+', ' ', text)  # Remove non-alphanumeric characters
        words_list = word_tokenize(text)
        filtered_words = [
            word for word in words_list
            if word not in stopwords.words('english')
            and len(word) > 2  # Only keep words longer than 2 characters
        ]

        text_results.extend(filtered_words)
    return text_results

def extract_keywords_tfidf(texts):
    vectorizer = TfidfVectorizer(max_features=20)
    X = vectorizer.fit_transform(texts)
    keywords = vectorizer.get_feature_names_out()
    return keywords

def extract_keywords_rake(texts):
    rake = Rake()
    rake.extract_keywords_from_text(' '.join(texts))
    keywords = rake.get_ranked_phrases()
    return keywords[:20]  # Return top 20 keywords

def process_video(video_path):
    frames = extract_frames(video_path)

    # Initialize YOLO model (assuming 'yolov8l-world.pt' exists in the current directory)
    model = YOLO('yolov8l-world.pt')

    # Detect objects in frames
    object_detections = detect_objects(model, frames)

    # Extract text from frames
    text_detections = extract_text(frames)

    # Combine object detections and text detections
    all_text = ' '.join(object_detections + text_detections)

    # Extract meaningful keywords using TF-IDF
    keywords_tfidf = extract_keywords_tfidf([all_text])

    # Extract meaningful keywords using RAKE
    keywords_rake = extract_keywords_rake(text_detections)

    # Combine keywords from both methods
    combined_keywords = set(keywords_tfidf) | set(keywords_rake)

    return combined_keywords

def main():
    base_url = 'https://d39w4p5b35gh50.cloudfront.net/'
    video_filenames = ['1.mp4', '2.mp4', '3.mp4', '4.mp4', '5.mp4']

    video_keywords = {}

    for filename in video_filenames:
        video_url = base_url + filename
        video_path = filename

        # Download video
        download_video(video_url, video_path)

        # Process video
        keywords = process_video(video_path)

        # Store keywords for this video
        video_keywords[filename] = keywords

        # Remove the downloaded video to save space
        os.remove(video_path)

    # Print keywords for each video
    for filename, keywords in video_keywords.items():
        print(f"Keywords for {filename}: {', '.join(keywords)}")

# Example usage
main()